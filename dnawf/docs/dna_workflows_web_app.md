# DNA Workflows Web App (Experimental)

DNA Workflows has been designed in a way maximise the reuse of code.  Each of the workflows modules could easily be loaded by other external scripts so long as they pass the two common, mandatory arguments; ```api``` and ```workflow_dict```.  The workflow execution engine follows a similar philosophy where the ```dna_workflows.py``` script behaves as a client and the ```wf_engine``` as a separate workflow execution engine.

For user convenience and to prevent the need for an over onerous system setup, ```dna_workflows.py``` will simply load the code from ```wf_engine.py``` as a python module and execute the entry point function ```run_wf()```, passing the ```workflow_db``` as a python dictionary when working in 'local' mode.  However, it is also possible to deploy the ```wf_engine.py``` code behind a web service and have the ```dna_workflows.py``` client send the ```workflow_db``` payload over the network.

**DISCLAIMER:** It should be noted at this stage that the Web App mode of operation is really only intended to allow rapid prototyping and **it has never been scrutinised from a security standpoint**.

The Web App solution comprises three (3) discrete containerised services;

 * A frontend ```flask``` web application to receive the ```workflow_db``` from the client.
 * A middleware RabbitMQ service to pass requests for workflow execution.
	 * ```docker run -d --hostname rabbit --name rabbit rabbitmq:3```
 * A backend task executor using ```dramatiq``` used to execute  ```wf_engine.run_wf()```.

Of course, there are lots of other options which could work equally as well (```celery``` and redis for example).

Before we start the container build we should know that ```wf_engine.py``` needs to be able to read the in the 'allowed' modules and functions that can be executed from a file called ```.modules```.  This is small security feature to prevent code injection and the file can be generated by the ```dna_workflows.py``` client using the ```--persist-module-manifest```.

Run the following command once before building the containers below to generate the ```.modules``` file;

```
python3 dna_workflows.py --offline --persist-module-manifest
```

Now go ahead and build the docker containers.

## Build the Containers

Dockerfile Web App;

```
FROM ubuntu:latest
RUN apt-get update && apt-get install python3 python3-pip -y
RUN pip3 install flask dramatiq pika
COPY webApp.py /
CMD python3 /webApp.py
```

then build like so;

```
docker build -f Dockerfile-webapp . --tag dna_workflows/webapp
```

Dockerfile Backend;

```
FROM ubuntu:latest
RUN apt-get update && apt-get install python3 python3-pip -y
RUN pip3 install dramatiq pika
COPY ./requirements.txt /
RUN pip3 install -r /requirements.txt
COPY ./ /
CMD dramatiq wf_engine_wrapper
```

and build like so;

```
docker build -f Dockerfile-backend . --tag dna_workflows/backend
```

## Run the Containers

Then we can run the three containers like so;

```
docker run --rm -d --hostname rabbit --name rabbit rabbitmq:3
RABBIT=`docker inspect -f '{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}' rabbit`
docker run --rm -d -e RABBIT=$RABBIT dna_workflows/backend
docker run --rm -d -e RABBIT=$RABBIT -p 5000:5000 dna_workflows/webapp:latest
```

For debugging you can use ```docker logs -f <container-id>``` on each of the container.

## Execute the Workflow

Now all you need to do is use the ```dna_workflows.py``` with the ```--host``` option and point towards the WebApp;

```
python3 dna_workflows.py --host 127.0.0.1:5000
```
